{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection: A Crisp DM Approach\n",
    "\n",
    "### Business Understanding\n",
    "\n",
    "Credit Card Fraud Detection is a classic class-imbalance problem where the number of fraud transactions is much lesser than the number of legitimate transaction for any bank. Most of the approaches involve building model on such imbalanced data, and thus fails to produce results on real-time new data because of overfitting on training data and a bias towards the majoritarian class of legitimate transactions. Thus, we can see this as an anomaly detection problem. \n",
    "\n",
    "1. What time does the Credit Card Frauds usually take place?\n",
    "2. What are the general trends of amounts for Credit Card Fraud Transactions?\n",
    "3. How do we balance the data to not let the model overfit on legitimate transactions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "!pip install mlxtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "The Dataset we use is the Kaggle Credit Card Fraud Detection Dataset enlisted in the following link: <a href=\"https://www.kaggle.com/mlg-ulb/creditcardfraud\">Link</a>\n",
    "\n",
    "- The Data has 32 features from V1-V28 which are unknown for confidentiality, TIme, Amount and Class\n",
    "- The input features are V1-V28, Time and Amount\n",
    "- The target variable is Class\n",
    "- The Data does not have any missing values as evident from the below mentioned code, thus need not be handled\n",
    "- The Data consists of all numerical features, and only the Target Variable Class is a categorical feature.\n",
    "    - Class 0: Legitimate Transaction\n",
    "    - Class 1: Fraud Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data into a Dataframe\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "- The Data does not have any missing values and hence, need not be handled.\n",
    "- The Data has only Target Variable Class as the categorical variable.\n",
    "- Remaining Features are numerical and need to be only standardized for comparison after balancing the dataset\n",
    "- The mean of the amount of money in transactions is 88.34\n",
    "- The standard deviation of amount of money in transactions is 250.12\n",
    "- The time is distributed throughout the data equitably and hence, serves as an independent feature\n",
    "- It is best to not remove or drop any data or features in this case and try to tune the model assuming them as independent features initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe Data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countplot_data(data, feature):\n",
    "    '''\n",
    "        Method to compute countplot of given dataframe\n",
    "        Parameters:\n",
    "            data(pd.Dataframe): Input Dataframe\n",
    "            feature(str): Feature in Dataframe\n",
    "    '''\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.countplot(x=feature, data=data)\n",
    "    plt.show()\n",
    "\n",
    "def pairplot_data_grid(data, feature1, feature2, target):\n",
    "    '''\n",
    "        Method to construct pairplot of the given feature wrt data\n",
    "        Parameters:\n",
    "            data(pd.DataFrame): Input Dataframe\n",
    "            feature1(str): First Feature for Pair Plot\n",
    "            feature2(str): Second Feature for Pair Plot\n",
    "            target: Target or Label (y)\n",
    "    '''\n",
    "    sns.FacetGrid(data, hue=target, height=6).map(plt.scatter, feature1, feature2).add_legend()\n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countplot_data(df, df.Class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "- The Dataset has 32 columns with unknown features labelled V1 to V28, Time, Amount and Class\n",
    "- The target variable is 'Class' and rest of the variables are input features\n",
    "- The Class has the following values:\n",
    "    - 0: Legitimate Transactions\n",
    "    - 1: Fraud Transactions\n",
    "- The Dataset is highly imbalanced as evident from the countplot with majoritarian class label '0' and minority class label '1'\n",
    "- Thus, if we run the model on such imbalanced data we may end up highly overfitting it on the data and resulting in non-deployable model\n",
    "- Hence, we will perform Synthetic Minority Oversampling on the data to balance it out as shown later after exploring other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is relationship of fraud transactions with amount of money?\n",
    "Let us try to determine the nature of transactions which are fraud and obtain a relevant set of the same with respect to their amount.\n",
    "- We hypothesise based on our scatter plot that all fraud transactions occur for an amount less than 2500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot_data_grid(df, \"Time\", \"Amount\", \"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot_data_grid(df, \"Amount\", \"Time\", \"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "- It can be observed that the fraud transactions are generally not above an amount of 2500.\n",
    "- It can also be observed that the fraud transactions are evenly distributed about time.\n",
    "- Let us try to prove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refine = df.copy()  # or filter it, e.g., df[df['Amount'] > 0]\n",
    "\n",
    "amount_more = 0\n",
    "amount_less = 0\n",
    "\n",
    "for i in range(df_refine.shape[0]):\n",
    "    if df_refine.iloc[i][\"Amount\"] < 2500:\n",
    "        amount_less += 1\n",
    "    else:\n",
    "        amount_more += 1\n",
    "\n",
    "print(\"Amount >= 2500:\", amount_more)\n",
    "print(\"Amount < 2500:\", amount_less)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_less = (amount_less/df.shape[0])*100\n",
    "percentage_less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we observe that the 99.85% of transactions amount to less than 2500.\n",
    "Let us see how many of these are fraud and others legitimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = 0\n",
    "legitimate = 1\n",
    "for i in range(df_refine.shape[0]):\n",
    "    if(df_refine.iloc[i][\"Amount\"]<2500):\n",
    "        if(df_refine.iloc[i][\"Class\"] == 0):\n",
    "            legitimate += 1\n",
    "        else:\n",
    "            fraud+=1\n",
    "print(fraud)\n",
    "print(legitimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refine = df[[\"Time\", \"Amount\", \"Class\"]]\n",
    "sns.pairplot(df_refine, hue=\"Class\", size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can conclude that since the number of fraud transaction below the amount of 2500 is same as the number of total fraud transactions. Hence, all fraud transactions are less than 2500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the relationship between Time and Transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(df_refine, hue=\"Class\", size=6).map(sns.distplot,\"Time\").add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above distribution plot, it is clear that the fraudulent transactions are spread throughout the time period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling\n",
    "- Study the Feature Correlations of the given data\n",
    "- Plot a Heatmap\n",
    "- Run GridSearch on the Data\n",
    "- Fine Tune the Classifiers\n",
    "- Create Pipelines for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "df_corr = df.corr()\n",
    "sns.heatmap(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train and Test Data in ratio 70:30\n",
    "X = df.drop(labels='Class', axis=1) # Features\n",
    "y = df.loc[:,'Class']               # Target Variable\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How will you balance the fraud and legitimate transactions in data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Synthetic Minority Oversampling\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mutual_infos = pd.Series(data=mutual_info_classif(X_res, y_res, discrete_features=False, random_state=1), index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_infos.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can say that the most correlated features after resolving class imbalance using Synthetic Minority Oversampling are V14, V10, V4, V12 and V17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We make use of AUC-ROC Score, Classification Report, Accuracy and F1-Score to evaluate the performance of the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of Classifiers\n",
    "def grid_eval(grid_clf):\n",
    "    \"\"\"\n",
    "        Method to Compute the best score and parameters computed by grid search\n",
    "        Parameter:\n",
    "            grid_clf: The Grid Search Classifier \n",
    "    \"\"\"\n",
    "    print(\"Best Score\", grid_clf.best_score_)\n",
    "    print(\"Best Parameter\", grid_clf.best_params_)\n",
    "    \n",
    "def evaluation(y_test, grid_clf, X_test):\n",
    "    \"\"\"\n",
    "        Method to compute the following:\n",
    "            1. Classification Report\n",
    "            2. F1-score\n",
    "            3. AUC-ROC score\n",
    "            4. Accuracy\n",
    "        Parameters:\n",
    "            y_test: The target variable test set\n",
    "            grid_clf: Grid classifier selected\n",
    "            X_test: Input Feature Test Set\n",
    "    \"\"\"\n",
    "    y_pred = grid_clf.predict(X_test)\n",
    "    print('CLASSIFICATION REPORT')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('AUC-ROC')\n",
    "    print(roc_auc_score(y_test, y_pred))\n",
    "      \n",
    "    print('F1-Score')\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    \n",
    "    print('Accuracy')\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters of each classifier are different\n",
    "# Hence, we do not make use of a single method and this is not to violate DRY Principles\n",
    "# We set pipelines for each classifier unique with parameters\n",
    "param_grid_sgd = [{\n",
    "    'model__loss': ['log'],\n",
    "    'model__penalty': ['l1', 'l2'],\n",
    "    'model__alpha': np.logspace(start=-3, stop=3, num=20)\n",
    "}, {\n",
    "    'model__loss': ['hinge'],\n",
    "    'model__alpha': np.logspace(start=-3, stop=3, num=20),\n",
    "    'model__class_weight': [None, 'balanced']\n",
    "}]\n",
    "\n",
    "pipeline_sgd = Pipeline([\n",
    "    ('scaler', StandardScaler(copy=False)),\n",
    "    ('model', SGDClassifier(max_iter=1000, tol=1e-3, random_state=1, warm_start=True))\n",
    "])\n",
    "\n",
    "MCC_scorer = make_scorer(matthews_corrcoef)\n",
    "grid_sgd = GridSearchCV(estimator=pipeline_sgd, param_grid=param_grid_sgd, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)\n",
    "\n",
    "\n",
    "grid_sgd.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_eval(grid_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(y_test, grid_sgd, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_jobs=-1, random_state=1))\n",
    "])\n",
    "param_grid_rf = {'model__n_estimators': [75]}\n",
    "grid_rf = GridSearchCV(estimator=pipeline_rf, param_grid=param_grid_rf, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)\n",
    "grid_rf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_eval(grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(y_test, grid_rf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "    ('model', LogisticRegression(random_state=1))\n",
    "])\n",
    "param_grid_lr = {'model__penalty': ['l2'],\n",
    "                 'model__class_weight': [None, 'balanced']}\n",
    "grid_lr = GridSearchCV(estimator=pipeline_lr, param_grid=param_grid_lr, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)\n",
    "grid_lr.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_eval(grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(y_test, grid_lr, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_knn = Pipeline([\n",
    "    ('model', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "param_grid_knn = {'model__p': [2]}\n",
    "grid_knn = GridSearchCV(estimator=pipeline_knn, param_grid=param_grid_knn, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)\n",
    "grid_knn.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_eval(grid_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(y_test, grid_knn, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- The K-Nearest Neighbors Classifier tuned with Grid Search with the best parameter being the Euclidean Distance (p=2) outperforms its counterparts to give a test accuracy of nearly 99.8% and a perfect F1-Score with minimal overfitting\n",
    "- SMOTE overcomes overfitting by synthetically oversampling minority class labels and is successful to a great degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- All Fraud Transactions occur for an amount below 2500. Thus, the bank can infer clearly that the fraud committers try to commit frauds of smaller amounts to avoid suspicion.\n",
    "- The fraud transactions are equitable distributed throughout time and there is no clear relationship of time with commiting of fraud.\n",
    "- The number of fraud transactions are very few comparted to legitimate transactions and it has to be balanced in order for a fair comparison to prevent the model from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
